# @package _global_

sampling_rate: 48000
length: 262144
channels: 2
upsampler_factor: 8
log_every_n_steps: 1000

model:
  _target_: main.module_upsampler.Model
  lr: 1e-4
  lr_beta1: 0.95
  lr_beta2: 0.999
  lr_eps: 1e-6
  lr_weight_decay: 1e-3
  use_scheduler: False
  scheduler_inv_gamma: 20000.0
  scheduler_power: 1.0
  scheduler_warmup: 0.99
  factor: ${upsampler_factor}
  in_channels: ${channels}
  channels: 128
  patch_size: 16
  resnet_groups: 8
  kernel_multiplier_downsample: 2
  kernel_sizes_init: [1, 3, 7]
  multipliers: [1, 2, 4, 4, 4, 4, 4]
  factors: [4, 4, 4, 2, 2, 2]
  num_blocks: [2, 2, 2, 2, 2, 2]
  attentions: [False, False, False, True, True, True]
  attention_heads: 8
  attention_features: 64
  attention_multiplier: 2
  use_nearest_upsample: False
  use_skip_scale: True
  use_attention_bottleneck: True
  diffusion_sigma_distribution:
    _target_: audio_diffusion_pytorch.LogNormalDistribution
    mean: -3.0
    std: 1.0
  diffusion_sigma_data: 0.2
  diffusion_dynamic_threshold: 0.0

datamodule:
  _target_: main.module_upsampler.Datamodule
  dataset:
    _target_: audio_data_pytorch.YoutubeDataset
    urls:
    # - https://www.youtube.com/watch?v=KE21kUtvRq8
    # - https://www.youtube.com/watch?v=YOgrH9-EXj4
    # - https://www.youtube.com/watch?v=D8VbcSqbdqw
    # - https://www.youtube.com/watch?v=k47pUjRw5Kw
    # - https://www.youtube.com/watch?v=WL9hX68FrTY
    # - https://www.youtube.com/watch?v=QLcSURSw5_0
    # - https://www.youtube.com/watch?v=ZQXPBNEwzEs
    # - https://www.youtube.com/watch?v=z5Ff8P9MDV0
    # - https://www.youtube.com/watch?v=VUHnVnFEglQ
    # - https://www.youtube.com/watch?v=inUCdKPOWUc
    # - https://www.youtube.com/watch?v=MvD-S41cTsc
    # - https://www.youtube.com/watch?v=hvkuGJU5yTs
    # - https://www.youtube.com/watch?v=WO7jvZQkM3o
    # - https://www.youtube.com/watch?v=2fiKEQUomM0
    # - https://www.youtube.com/watch?v=WUj_lT1pqyI
    # - https://www.youtube.com/watch?v=lMIKYCxPBps
    # - https://www.youtube.com/watch?v=6E4ClZ_LFVM
    # - https://www.youtube.com/watch?v=_I7fGMymbKI
    # - https://www.youtube.com/watch?v=v_F8HsFPsfs
    # - https://www.youtube.com/watch?v=nczHqJSgvqY
    # - https://www.youtube.com/watch?v=uk0LwRWimak
    # - https://www.youtube.com/watch?v=Fk1Mvz7SDcs
    # - https://www.youtube.com/watch?v=xwhIYB2ACyw
    # - https://www.youtube.com/watch?v=U9mJ1wjHiDo
    # - https://www.youtube.com/watch?v=VrV3ePBzAJI
    # - https://www.youtube.com/watch?v=lR6kddY9yeg
    # - https://www.youtube.com/watch?v=yaq5amPQrdk
    # - https://www.youtube.com/watch?v=R23Uuy0DPz4
    # - https://www.youtube.com/watch?v=1WMFGCVt1j4

    - https://www.youtube.com/watch?v=4Gn9lLoYG9E
    - https://www.youtube.com/watch?v=5V-8Lw7uN0I
    - https://www.youtube.com/watch?v=fe_blX3zKvg
    - https://www.youtube.com/watch?v=FTxdNDfSe8g
    - https://www.youtube.com/watch?v=ewW3_TIoBLI
    - https://www.youtube.com/watch?v=WIcgGoDFJLU
    - https://www.youtube.com/watch?v=k4pwIuGw6IE
    - https://www.youtube.com/watch?v=6NkVTb-l1AA
    - https://www.youtube.com/watch?v=oepITIocXTY
    - https://www.youtube.com/watch?v=WnfA6-sZiZU
    root: ${data_dir}
    crop_length: 12 # seconds crops
    transforms:
      _target_: audio_data_pytorch.AllTransform
      source_rate: ${sampling_rate}
      target_rate: ${sampling_rate}
      random_crop_size: ${length}
      loudness: -20
  val_split: 0.01
  batch_size: 2
  num_workers: 8
  pin_memory: True

callbacks:
  rich_progress_bar:
    _target_: pytorch_lightning.callbacks.RichProgressBar

  model_summary:
    _target_: pytorch_lightning.callbacks.RichModelSummary
    max_depth: 2

  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "valid_loss"   # name of the logged metric which determines when model is improving
    save_top_k: 1           # save k best models (determined by above metric)
    save_last: True         # additionaly always save model from last epoch
    mode: "min"             # can be "max" or "min"
    verbose: False
    dirpath: ${logs_dir}/ckpts/${now:%Y-%m-%d-%H-%M-%S}
    filename: '{epoch:02d}-{valid_loss:.3f}'

  ema:
    _target_: main.module_upsampler.EMA
    decay: 0.9999
    update_after_n_steps: 1000
    update_every_n_steps: 1

  learning_rate_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor

  audio_samples_logger:
    _target_: main.module_upsampler.SampleLogger
    num_items: 3
    factor: ${upsampler_factor}
    channels: ${channels}
    sampling_rate: ${sampling_rate}
    length: ${length}
    sampling_steps: [3,5,10,25,50]
    diffusion_sampler:
      _target_: audio_diffusion_pytorch.ADPM2Sampler
      rho: 1.0
    diffusion_schedule:
      _target_: audio_diffusion_pytorch.KarrasSchedule
      sigma_min: 0.0001
      sigma_max: 3.0
      rho: 9.0

loggers:
  wandb:
    _target_: pytorch_lightning.loggers.wandb.WandbLogger
    project: ${oc.env:WANDB_PROJECT}
    entity: ${oc.env:WANDB_ENTITY}
    # log_model: "all"
    # offline: False  # set True to store all logs only locally
    job_type: "train"
    group: ""
    save_dir: ${logs_dir}

trainer:
  _target_: pytorch_lightning.Trainer
  gpus: 1 # Set `1` to train on GPU, `0` to train on CPU only, and `-1` to train on all GPUs, default `0`
  precision: 32 # Precision used for tensors, default `32`
  accelerator: gpu # `ddp` GPUs train individually and sync gradients, default `None`
  min_epochs: 0
  max_epochs: -1
  enable_model_summary: False
  log_every_n_steps: 1 # Logs metrics every N batches
  check_val_every_n_epoch: null
  val_check_interval: ${log_every_n_steps}
